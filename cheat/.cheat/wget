# Download a single file
wget http://path.to.the/file

# Download a file and change its name
wget http://path.to.the/file -o newname

# Download a file into a directory
wget -P path/to/directory http://path.to.the/file

# Continue an aborted downloaded
wget -c http://path.to.the/file

# Download multiples files with multiple URLs
wget URL1 URL2

# Parse a file that contains a list of URLs to fetch each one
wget -i url_list.txt

# Mirror whole page 
wget -pk http://path.to.the/page.html

# Mirror whole site 
wget -mk http://www.server.com/

# Mirror whole site (in more human appearing way)
wget --wait=20 --limit-rate=20K -r -p -U Mozilla http://www.server.com

# Download files according to a pattern
wget http://www.myserver.com/files-{1..15}.tar.bz2

# Download all the files in a directory with a specific extension if directory indexing is enabled
wget -r -l1 -A.extension http://myserver.com/directory
wget -r -l1 -H -t1 -nd -N -np -A.mp3 -erobots=off http:://myserver.com/directory

# Allows you to download just the headers of responses (-S --spider) and display them on Stdout (-O -).
wget -S --spider -O - http://google.com

# Change the User-Agent to 'User-Agent: toto'
wget -U 'toto' http://google.com
